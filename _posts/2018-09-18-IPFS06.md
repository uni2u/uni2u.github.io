---
layout: post
title: "IPFS 프로토콜 Kademlia 기본 모델 계층 분석"
categories:
  - ipfs
  - Distributed File System
  - Kademlia
tags:
  - ipfs
  - kademlia
lang: ko
author: "uni2u"
meta: "Springfield"
---

# 분산 시스템

기존의 라우팅 프로토콜에서는 다른 노드를 찾는 서비스를 제공하는 중앙 집중식 서버가 존재합니다. 상호 연결을 구현해야하는 경우 동일한 중앙 서버에 등록해야 합니다. 이러한 방식으로, 사용자의 고유 식별 정보에 기초하여 두 당사자에 대한 연결이 성립 될 수있습니다. 분산 시스템에서는 어느 누구도 각 노드의 정보를 관리하지 못합니다. 노드와 노드는 상호 연결되어야 합니다. 특정 알고리즘과 방법을 통해 서로를 찾고, 서로를 식별하고 연결을 설정해야 합니다. 각 노드에는 온라인 네트워크 노드를 나타내는 고유 `node_id` 가 있습니다.

![분산 시스템](/images/ipfs_kademlia_01.png)

## Kademlia 기본 모델

네트워크의 다른 노드를 빠르게 찾고 네트워크 연결 관계를 유지하려면 현재 노드와 다른 노드 사이의 거리를 계산해야 합니다. kademlia DHT 디자인에서  XOR 연산을 사용하여 거리를 계산합니다. 노드 간의 거리와 거리를 기반으로 네트워크 라우팅 정보를 유지하는 방법은 물리적 거리가 아니라 노드 ID 사이의 비트 거리입니다.

### XOR 연산

![XOR 연산](/images/ipfs_kademlia_02.png)

첫 번째 연산은 XOR 연산이며, 두 비트의 값이 같으면 XOR 연산의 결과는 `0` 입니다. 두 비트의 값이 다른 경우 연산 결과는 `1` 이되고 두 네트워크 노드의 ID를 기반으로 이와 같이 계산합니다. 거리는 그림과 같이 노드 x의 id 값이 _0011_ 인 것으로 가정하고, 대상 노드 _1110_ 사이의 거리를 계산하면 결과는 _1101_ 입니다. 이 연산을 기반으로 다음과 같은 계산을 유도합니다.

![이웃노드 탐색](/images/ipfs_kademlia_03.png)

위 그림에서 A 노드 ID에서 다른 노드 ID를 찾는 과정을 간단하게 나열하면 다음과 같습니다.

- 0번째 비트가 있는 A 노드에는 _1_ 이 있음
- 처음 세자리는 _001_ 이며 마지막만 다른 노드 즉, ID가 _0010_ 인 노드가 있을 수 있음
  - 해당 노드는 XOR 연산에 따라 거리가 '1' 임을 알 수 있음
- 1번째 비트를 위와 같이 바라보면 노드와 다른 ID를 가진 노드는 2가지가 있을 수 있음
  - _0000_, _0001_ 임을 알 수 있음
  - 즉, 노드 ID가 _00_ 으로 시작하는 노드가 있음을 알 수 있음
- 2번째 비트를 위와 같이 바라보면 노드와 다른 ID를 가진 노드는 4가지가 있을 수 있음
  - _0100_, _0101_, _0110_, _0111_ 임을 알 수 있음
  - 즉, 노드 ID가 _0_ 으로 시작하는 노드가 있음을 알 수 있음
- 3번째 비트를 위와 같이 바라보면 노드와 다른 ID를 가진 노드는 8가지가 있을 수 있음
  - _1000_, _1001_, _1010_, _1011_, _1100_, _1101_, _1110_, _1111_ 임을 알 수 있음
  - 즉, 노드 ID가 _1_ 로 시작하며 노드 ID와 공통 시작점을 가지고 있지 않음
- 이러한 계산을 통하여 A 노드 _0011_ 과의 거리에 따라 다른 카테고리로 나눌 수 있음
  - 0번째 비트와의 거리는 '1'
  - 1번째 비트와의 거리는 '2~3'
  - 2번째 비트와의 거리는 '4~7'
  - 3번째 비트와의 거리는 '8~15'

즉, i 번째부터 시작하는 노드와의 거리는 현재 노드의 [2^i, 2^{i+1}] 입니다. 이를 이진트리 형식으로 표현하면 다음과 같습니다.

![이진트리](/images/ipfs_kademlia_04.png)

영역 1, 2, 3 및 4 는 위 그림의 0, 1, 2 및 3 번째 비트에서 자신의 노드 0011의 id와 다른 노드 그룹에 해당합니다. 이진트리의 경로는 노드 번호의 각 비트의 값으로 나타냅니다. 리프 노드는 네트워크 노드 번호이며 그 값은 루트 노드에서 리프 노드까지의 경로입니다.

![거리계산](/images/ipfs_kademlia_05.png)

위의 디자인 다이어그램에서 src 노드에서 dst 노드를 찾을 때 먼저 위의 지식을 기반으로 src 노드와 dst 노드 사이의 거리를 계산 한 다음 거리와 일치하는 노드 그룹을 찾습니다. 자신의 하프 존에없는 노드와 자신보다 거리가 절반 정도 짧은 대상 노드인 a 노드를 찾습니다. a 노드는 자신의 라우팅 거리 테이블에서 dst 노드까지 거리보다 절반 짧은 노드인 b 노드를 찾습니다. b 노드는 반복적으로 dst 노드를 찾을 수 있도록 합니다.

이 방법으로 경로를 찾으면 전체 네트워크에 n개의 노드가 있는 경우 최악 검색 속도는 n의 2 로그입니다. 이 알고리즘은 매우 빠른 검색 알고리즘입니다. 노드가 100만 개이면 검색은 최대 20회만에 대상 노드를 찾을 수 있습니다.

즉, _0011_ 노드가 _1100_ 노드를 찾는 경우 '1' 로 시작되는 모든 노드 정보를 알 필요 없이 '1'로 시작되는 노드 하나만 알면되고, 그 노드를 통해 _1100_ 의 행방을 수소문 하면 되는 것입니다. 결론적으로 Kademlia는 모든 정보를 가지고 있을 수 없는 거대한 집합군에서 특정 노드를 빠르게 O(log2(n)) 찾기 위한 방식입니다. 

### k-bucket

![라우팅 저장 정보](/images/ipfs_kademlia_06.png)

이전 섹션에서는 id가 _0011_ 인 네트워크 노드의 경우 라우팅 테이블에 저장된 정보는 위 그림과 같습니다. 위 그림은 네트워크 ID에 대하여 4가지 비트를 비교하고 모든 노드 정보를 저장하고 있습니다. 그러나 네트워크의 ID가 160 비트까지 늘어나는 경우를 생각한다면 각 노드에 대한 정확한 정보를 저장하는 것은 필요하지 않습니다. ID의 모든 노드가 항상 온라인 상태가 아니므로 많은 데이터 일관성 문제가 발생합니다.

IPFS는 이러한 문제를 해결하기 위해 k-buckets 디자인을 적용하였습니다. 이 디자인의 원칙은 로컬 노드와의 거리에 따라 다른 ID 공간의 노드를 그룹화하고, 각 그룹은 최대 K 개의 노드 정보를 저장할 수 있습니다. 예를들어 4비트 ID 공간 주소라면 K = 3 인 경우, 노드는 아래에 도시 된 바와 같이 라우팅 정보를 저장합니다.

![k-buckets](/images/ipfs_kademlia_07.png)

위 그림에서 비트로 나뉜 각 그룹은 최대 K 개의 노드 정보를 저장합니다. k-buckets 디자인을 적용하면 각 노드가 저장할 정보의 양을 줄일 수 있습니다. 유효거리가 가까운 노드인 경우 (온라인이 아니거나 노드 정보가 작성되지 않는 경우 포함) 정보를 저장하지 않습니다. 위 그림에서는 그룹 '0' 번이 이에 해당됩니다. '3' 번 그룹의 경우 전체 네트워크 노드 ID 공간의 절반을 담당하기 때문에 온라인 노드 정보를 사용할 수 있습니다.

노드를 찾을 때 적절한 그룹으로 이동하여 노드를 선택하여 대상 노드에 대한 정보를 요청합니다. 예를들어 a 노드 그룹이 K 보다 작거나 같은경우 a 노드는 목적지 노드를 찾는데 도움이 됩니다. 검색 프로세스에서 a 노드가 응답하지 않으면 노드 정보를 그룹에서 제거합니다. 응답이 있는 경우 그룹의 k-buckets 큐 끝에 노드를 놓습니다. 즉, 마지막으로 저장된 정보는 최근에 사용 가능함이 입증된 노드 입니다. 네트워크 라우팅 과정에서 노드가 사용 가능한 것으로 판명(자신의 k-buckets 대기열 중 하나에 속함)되면 다음 노드 정보가 대기열의 끝에 위치합니다. 그러나 대기열에 K 개 노드 이상이 있는 경우 큐의 시작부분 노드가 사용 가능한지 확인합니다. 연결되어 있는 경우라면 새로 발견된 노드는 버립니다. 연결되어있지 않는 것으로 판명되면 대기열에서 사용할 수 없는 노드를 제거한 뒤 새로 발견된 노드 정보를 대기열 마지막으로 둡니다.

이를 테스트하면 다음과 같은 그래프를 얻을 수 있습니다.

![시간증가에 따른 온라인 상태](https://upload-images.jianshu.io/upload_images/3163404-c41fc280a99bf89b?imageMogr2/auto-orient/strip%7CimageView2/2/w/640/format/webp)

위 그래프에서 x 축은 시간을 의미하고 y 축은 한 시간전에 노드가 온라인 상태일 확률을 나타냅니다. 즉, 온라인 시간이 길수록 노드가 온라인 상태를 유지하는 경향이 있습니다. 따라서 새로 발견 된 노드를 버리고 아직 온라인 상태인 오래된 노드를 업데이트하는 전략을 사용하여야 합니다. 이 전략의 또 다른 장점은 DOS 공격에 대한 강력한 방어 수단이 있다는 것입니다. DOS 공격이 발생하면 새로운 공격 노드가 이전 온라인 노드 상태로 보이게 할 수 없습니다. 또한 새로운 공격 노드의 링크 요청이나 라우팅 정보를 삭제할 수 있습니다.

### IPFS에서 Kademlia 활용

Kedamlia 프로토콜은 `PING`, `STORE`, `FIND_NODE`, `FIND_VALUE` 네 가지 유형의 명령을 지원합니다.

`PING`은 ID에 대한 노드가 온라인인지 여부를 확인하고 `STORE`는 이러한 데이터를 저장 용 노드로 전달합니다. `FIND_NODE`는 ID에 따라 ID에 대한 네트워크 노드 정보를 조회하는 것으로, 실제 네트워크 환경에서는 검색된 노드의 ID가 온라인이 아니거나 생성되지 않는 경우가 발생할 수 있기 때문에 노드를 찾는 명령이 검색으로 진화합니다. K 거리는 ID에 가장 가까운 노드에 의해 발견됩니다. K 노드는 동일한 k-buckets 리스트에서 찾을 수 있거나, k-buckets이 만족되지 않으면 가장 가까운 k-buckets 에서 찾을 수 있습니다.

`FIND_VALUE`는 `FIND_NODE`와 유사하지만 검색 과정에서 K 노드가 발견되기 전에 내용을 찾았을 가능성이 있습니다. 일부 내용은 캐시되고 VALUE를 저장하는 노드는 직접 내용을 반환하기 때문에 프로세스가 종료됩니다.

위의 네 가지 지침을 처리 할 때 모든 메시지 수신자는 네트워크 주소 위조를 방지하기 위해 임의의 RPC ID를 반환합니다.

특정 노드 ID에 가장 근접한 K 개의 노드를 찾을 때, K 개의 목표 노드를 찾기 위해 반복 접근법이 사용됩니다. 먼저, 라우팅 테이블로부터, 자신에게 가장 가까운 k-buckets 목록에 있는 노드를 찾은 후 동시에 조회 요청을 시작합니다. 예를들어 a의 값은 1, 2, 3이 될 수 있습니다. k-buckets의 용량 K가 3이기 때문입니다. 그러므로 같은 k-bucket으로 물어 보는 것이 가장 좋습니다. a = 1 일 때, 룩업 프로토콜은 Chord 네트워크로 진화합니다. 노드의 정보를 질의함으로써, 검색자는 수용된 질의 결과에 따라 가장 가까운 거리를 갖는 새로 발견 된 노드에 검색 명령을 재전송 할 수 있습니다. K 개의 거리 타겟 탐색 노드들에 가장 가까운 노드들로부터, 탐색 정보를 전송하지 않은 노드를 연속적으로 찾고, 이들에게 탐색 명령을 전송합니다. 이러한 노드가 올바르게 응답하지 않거나 오프라인 상태이면 라우팅 정보 테이블에서 노드 정보가 삭제됩니다. 이 프로세스에서 현재 K 노드보다 대상 노드에 더 가까운 노드가 발견되지 않으면 K 노드로 계속 진행하며 조회 명령을 전송하지 않은 나머지 노드는 계속 조회 명령을 전송합니다. 검색 프로세스는 룩업 노드가 타겟 노드에 가장 근접하게 접촉 할 수 있는 K 노드 정보를 찾으면 종료합니다.

데이터를 저장할 때 가장 가까운 K 개의 거리 키가있는 노드를 찾고 저장 명령을 보내면 저장된 발신자는 라우팅 데이터의 견고성을 보장하기 위해 24 시간마다 저장 명령을 브로드캐스트합니다.

데이터를 검색하는 과정에서 캐시를 만날 것이고, K 개의 가장 가까운 노드를 찾기 전에 키의 값을 찾을 것 입니다. 그러면 매우 빨리 데이터를 찾을 수 있습니다. 그러나 데이터 과열, 즉 너무 많은 사람이 데이터를 캐시하는 것을 방지하기 위해 대상 노드와의 캐시 거리의 거리에 따라 주기적으로 캐시 내용이 삭제되고 대상 노드로부터 더 먼 캐시가 더 빨리 삭제됩니다.

전달 된 노드의 모든 요청 및 데이터는 노드가 로컬 라우팅 정보를 업데이트하는 것을 도울 수 있습니다. 그러나 인기없는 라우팅 정보 중 아무도 액세스하지 못하면 데이터가 매우 냉각됩니다. 라우팅 정보가 너무 냉각되는 것을 방지하기 위해 노드는 ID를 하나씩 무작위로 선택하고 그에 대한 검색 요청을 시작합니다. 이것은 노드의 따뜻함을 보장할 수 있습니다. 이 검색 프로세스는 조회되는 ID에 대해 자신과 다른 해당 노드를 업데이트 할 수 있습니다.

네트워크에 새로 결합 된 노드 U-Node는 이미 네트워크에서 실행중인 하나의 노드 W-node를 알고 있어야 합니다. 새로운 노드 U-Node는 먼저 자신의 k-bucket 큐에 W-node를 추가하고 ID에 대한 조회 요청을 시작합니다. 이런 과정에서 다른 노드가 응답하게 됩니다. 새 노드는 전체 네트워크의 토폴로지를 업데이트하고 다른 노드가 이 최신 노드에 대한 라우팅 정보를 업데이트 합니다.

### Kademlia 라우팅 트리 생성 프로세스

첫째, k-buckets 라우팅 정보는 이진트리 형식으로 저장되며 이진트리의 생성은 동적이며 이진트리 데이터 구조는 발견된 노드의 ID에 따라 동적으로 조정됩니다. 다음은 동적 생성 프로세스를 설명하기 위한 노드 번호가 _0000_ 인 빈 이진트리의 예입니다.

![비어있는 이진트리 예](/images/ipfs_kademlia_08.png)

예 1에서 새롭게 발견 된 첫 번째 노드 ID 번호의 첫 번째 비트가 1이면, 두 번째 k-buckets가 생성되고, 하나는 첫 번째 비트가 '1'인 노드 ID의 정보를 저장합니다. 첫 번째 비트가 '0'을 갖는 다른 ID, 이 k-buckets에 의해 커버되는 ID의 공간은 현재 노드 _0000_ 을 포함합니다.

예 2에서 첫 번째 노드의 ID 번호가 새로 발견되면 첫 번째 비트는 '0'이고 현재 노드 ID 번호는 _0000_ 의 첫 번째 비트와 같고 두 번째 비트는 1이며 현재 노드 ID 비트의 두 번째 값이 다르면 두 개의 k-buckets이 생성되고 '00' 및 '01'로 시작하는 ID 정보를 나타냅니다.

위 내용은 두가지 예로 설명할 수 있습니다. 이진트리에서 처음에 새로 추가 된 노드와 현재 노드 번호를 주로 판단하고 새롭게 추가된 노드의 ID가 현재 노드 ID를 커버하는 k-buckets 범위 내에 있으면 현재 노드 ID가 있는 영역을 2K 버킷으로 분할합니다. 그런다음 원래 규칙에 따라 새로운 k-buckets 그룹에 가입됩니다. 새로 추가된 노드 ID가 현재 노드 ID가 위치한 k-buckets 공간과 다른 경우, 자신에 속한 k-buckets 이진트리에 따라 검색되고, 큐가 가득 찼으면 이전 논리에 따라 추가되거나 삭제됩니다.

![이진트리 동적 생성 프로세스](/images/ipfs_kademlia_09.png)

위의 그림은 세 개의 노드가 특정 순서로 추가 될 때 이진트리의 간단한 동적 생성 프로세스를 보여줍니다. 슬래시의 k-buckets는 노드 ID가 없는 ID 공간을 나타내며 그리드의 k-buckets는 노드 ID가 있는 ID 공간을 나타냅니다. 신규 노드의 ID가 합류 전에 현재 ID가 위치하는 ID 공간과 일치하는 경우, 분할 노드의 ID 공간은 2 개의 리프 노드가 됩니다.

![이진트리 동적 조인 프로세스](/images/ipfs_kademlia_10.png)

네트워크에있는 모든 노드의 ID가 _001_ 로 시작하는 경우 이 노드를 _000_ 개 추가하면 이진 트리의 원래 구조는 논리에 따라 삭제해야 합니다. 원래 논리는 k-buckets에서 각 그룹화 노드의 총 수는 K를 초과 할 수 없습니다. 위의 그림에서 노드 _0000_ 의 경우 빨간색 상자의 노드는 k-buckets 통합 표현이어야하며 여러 노드는 삭제해야 합니다. 버킷이 K 노드를 초과 할 수 없다는 한계를 충족 시키지만 라우팅 정보가 손실됩니다. 이 문제를 해결하기 위해 kademlia는 원래의 첫 번째 노드와 새 노드가 생성 된 이진트리 구조를 직접 새로운 이진트리에 연결하므로 새로운 노드 조인 전에 라우팅 구조가 유지 될 수 있습니다.

Key-Value 데이터 저장 장치의 유효성과 장기적인 성질을 보장하기 위해 노드는 주기적으로 키 정보를 브로드캐스팅해야 합니다. 정보가 정기적으로 업데이트되지 않으면 Key-Value를 수락하는 노드가 정보를 저장하거나 노드가 오프라인 상태가 되거나 새로운 노드가 온라인 상태이고 ID 값이 현재 K 노드보다 데이터 게시자에 더 가깝지만 데이터에 대한 정보가 없을 수 있습니다. 위의 두 가지 조건으로 인해 데이터가 검색되지 않을 수 있습니다.

이 문제를 해결하기 위해 간격을 두고 매시간마다 데이터를 저장하는 K 노드가 다른 K-1 노드에서 최신 온라인 상태를 얻기위한 조회 명령을 수행할 수 있습니다. 이것은 필요없는 소비 입니다. 이 간단한 모델을 사용하면 뛰어난 최적화로 프로세스를 훨씬 저렴하게 만들 수 있습니다. 노드가 룩업 명령을 수신하면, 다른 K-1 노드가 동일한 명령을 수신 하였으므로, 명령을 수신 한 노드는 자신의 시간을 업데이트하고 다음 시간에 탐색을 수신하지 않도록 타이밍을 설정합니다. 명령어의 경우에는 실제로 룩업 명령어를 발행하므로 실제로 동일한 시간 내에 특정 데이터 쌍의 룩업 명령어에 대해 하나의 노드 만 발행됩니다. 이렇게하면 시스템의 메시지 수가 크게 줄어 듭니다.

또 다른 메커니즘은 k-buckets가 분할 될 때 특정 ID 값의 마지막 K 개 노드의 라우팅 정보를 다시 정렬하고 업데이트해야 한다는 것입니다. 이 프로세스는 타이밍 검색의 명령을 어느 정도 완화합니다.
